{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\pishing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir:Path\n",
    "    file_path:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phishingdetection.constants import *\n",
    "from phishingdetection.utils.common import read_yaml, create_directories\n",
    "from phishingdetection.logging import logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            file_path=config.file_path,\n",
    "            # Add other attributes as needed from your ModelTrainerConfig class\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def input_data(self):\n",
    "        logging.info(\"Splitting training and test input data\")\n",
    "        train_data = pd.read_csv(r\"artifacts\\data_transformation\\train_scaled.csv\")\n",
    "        test_data = pd.read_csv(r\"artifacts\\data_transformation\\test_scaled.csv\")\n",
    "        logging.info(\"Split training and test input data\")\n",
    "        X_train, y_train, X_test, y_test = (\n",
    "            train_data.iloc[:, :-1],\n",
    "            train_data.iloc[:, -1],\n",
    "            test_data.iloc[:, :-1],\n",
    "            test_data.iloc[:, -1]\n",
    "        )\n",
    "        \n",
    "        models = [\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            RidgeClassifier(alpha=0.005),\n",
    "            LinearSVC(dual=False),\n",
    "            SVC(),\n",
    "            KNeighborsClassifier(n_neighbors=5),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            MLPClassifier()\n",
    "        ]\n",
    "            \n",
    "        \n",
    "        return X_train, y_train, X_test, y_test, models\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def input_data(self):\n",
    "        logging.info(\"Splitting training and test input data\")\n",
    "        train_data_scaled = pd.read_csv(r\"artifacts\\data_transformation\\train_scaled.csv\")\n",
    "        test_data_scaled = pd.read_csv(r\"artifacts\\data_transformation\\test_scaled.csv\")\n",
    "        train_data=pd.read_csv(r\"artifacts\\data_transformation\\train_y_scaled.csv\")\n",
    "        test_data=pd.read_csv(r\"artifacts\\data_transformation\\test_y_scaled.csv\")\n",
    "        logging.info(\"Split training and test input data\")\n",
    "        X_train, y_train, X_test, y_test = (\n",
    "            train_data_scaled.iloc[:, :],\n",
    "            train_data.iloc[:,:],\n",
    "            test_data_scaled.iloc[:, :],\n",
    "            test_data.iloc[:, :]\n",
    "        )\n",
    "        \n",
    "        models = [\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            RidgeClassifier(alpha=0.005),\n",
    "            LinearSVC(dual=False),\n",
    "            SVC(),\n",
    "            KNeighborsClassifier(n_neighbors=5),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            MLPClassifier()\n",
    "        ]\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, models\n",
    "\n",
    "    def model_selection(self, X_train, y_train, X_test, y_test, models):\n",
    "        accuracy_result = []\n",
    "        precision_result = []\n",
    "        models_dict = {}\n",
    "\n",
    "        for model in models:\n",
    "            model.fit(X_train, y_train.values.ravel())\n",
    "            y_pred = model.predict(X_test)\n",
    "            precision = precision_score(y_test, y_pred, average='micro')\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracy_result.append(accuracy)\n",
    "            precision_result.append(precision)\n",
    "            models_dict[str(model)] = {'model': model, 'accuracy': accuracy, 'precision': precision}\n",
    "\n",
    "        return pd.DataFrame({'models': list(models_dict.keys()), 'accuracy': accuracy_result, 'precision': precision_result}), models_dict\n",
    "\n",
    "    def save_models(self, models_dict):\n",
    "        logging.info(\"Saving models to file\")\n",
    "        with open(self.config.file_path, 'wb') as f:\n",
    "            pickle.dump(models_dict, f)\n",
    "        logging.info(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-09 14:57:08,216: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-04-09 14:57:08,218: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-09 14:57:08,221: INFO: common: created directory at: artifacts]\n",
      "[2024-04-09 14:57:08,223: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2024-04-09 14:57:08,224: INFO: 3652498402: Splitting training and test input data]\n",
      "[2024-04-09 14:57:08,532: INFO: 3652498402: Split training and test input data]\n",
      "[2024-04-09 15:03:15,555: INFO: 3652498402: Saving models to file]\n",
      "[2024-04-09 15:03:15,655: INFO: 3652498402: Models saved successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    X_train, y_train, X_test, y_test,models = model_trainer_config.input_data()\n",
    "    models_dict= model_trainer_config.model_selection(X_train, y_train, X_test, y_test, models)\n",
    "    model_trainer_config.save_models(models_dict)\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70917, 22) (70917, 1) (17730, 22) (17730, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70912</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70913</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70914</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70915</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70916</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70917 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       phishing\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             1\n",
       "4             1\n",
       "...         ...\n",
       "70912         1\n",
       "70913         0\n",
       "70914         1\n",
       "70915         0\n",
       "70916         1\n",
       "\n",
       "[70917 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Check what keys are present in the loaded data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys in the pickle file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Assuming the models are stored under a key named 'models'\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Print or iterate through the list of models\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the .pkl file\n",
    "with open('artifacts\\model_trainer\\model_selection.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Check what keys are present in the loaded data\n",
    "print(\"Keys in the pickle file:\", data.keys())\n",
    "\n",
    "# Assuming the models are stored under a key named 'models'\n",
    "if 'models' in data:\n",
    "    # Print or iterate through the list of models\n",
    "    print(\"List of models:\")\n",
    "    for model in data['models']:\n",
    "        print(model)\n",
    "else:\n",
    "    print(\"No 'models' key found in the pickle file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_models.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m data\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the pickle file\n",
    "with open('saved_models.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts\\\\model_trainer\\\\model_selection.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the data from the pickle file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martifacts\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_trainer\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_selection.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Step 1: Check the type of loaded data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts\\\\model_trainer\\\\model_selection.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open('artifacts\\model_trainer\\model_selection.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Step 1: Check the type of loaded data\n",
    "print(\"Type of loaded data:\", type(data))\n",
    "\n",
    "# Step 2: Inspect the loaded data\n",
    "print(\"Loaded data:\", data)\n",
    "\n",
    "# Step 3: Access the 'models' dictionary if present\n",
    "if isinstance(data, dict):\n",
    "    models_dict = data.get('models')\n",
    "    if models_dict is not None:\n",
    "        # Now you can proceed to check the types of values associated with each key in models_dict\n",
    "        for key, value in models_dict.items():\n",
    "            print(\"Key:\", key, \"Value type:\", type(value))\n",
    "    else:\n",
    "        print(\"The loaded data does not contain a 'models' dictionary.\")\n",
    "else:\n",
    "    print(\"The loaded data is not a dictionary.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Access the models dictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "with open('models.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# Access the models dictionary\n",
    "models_dict = data['model']\n",
    "\n",
    "# Assuming index 5 contains the trained DecisionTreeClassifier model\n",
    "best_model = models_dict\n",
    "\n",
    "# Now you can use the best_model for prediction\n",
    "# For example, if you have some new data 'X_test', you can predict using:\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are saved in the file.\n"
     ]
    }
   ],
   "source": [
    "# Check if the second element of the loaded data is a dictionary\n",
    "if isinstance(data[1], dict):\n",
    "    print(\"Models are saved in the file.\")\n",
    "else:\n",
    "    print(\"Models are not saved in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(max_iter=1000), Accuracy: 0.8932148767528961, Precision: 0.8932148767528961\n",
      "Model: RidgeClassifier(alpha=0.005), Accuracy: 0.8767528960891908, Precision: 0.8767528960891908\n",
      "Model: LinearSVC(dual=False), Accuracy: 0.8966117933977876, Precision: 0.8966117933977876\n",
      "Model: SVC(), Accuracy: 0.8927793746189356, Precision: 0.8927793746189356\n",
      "Model: KNeighborsClassifier(), Accuracy: 0.9324971692361292, Precision: 0.9324971692361292\n",
      "Model: DecisionTreeClassifier(), Accuracy: 0.9324971692361292, Precision: 0.9324971692361292\n",
      "Model: RandomForestClassifier(), Accuracy: 0.9574078912986673, Precision: 0.9574078912986673\n",
      "Model: AdaBoostClassifier(), Accuracy: 0.9043637313822838, Precision: 0.9043637313822838\n",
      "Model: MLPClassifier(), Accuracy: 0.9383328978311993, Precision: 0.9383328978311993\n",
      "Specific Model: LogisticRegression(max_iter=1000), Accuracy: 0.8932148767528961, Precision: 0.8932148767528961\n"
     ]
    }
   ],
   "source": [
    "# Access the models dictionary from the loaded data\n",
    "models_dict = data[1]\n",
    "\n",
    "# Now you can access each model object along with its associated metrics\n",
    "for model_name, model_data in models_dict.items():\n",
    "    model = model_data['model']\n",
    "    accuracy = model_data['accuracy']\n",
    "    precision = model_data['precision']\n",
    "    print(f\"Model: {model_name}, Accuracy: {accuracy}, Precision: {precision}\")\n",
    "\n",
    "# You can also access a specific model by its name\n",
    "specific_model_name = 'LogisticRegression(max_iter=1000)'  # Example model name\n",
    "specific_model_data = models_dict.get(specific_model_name)\n",
    "if specific_model_data:\n",
    "    specific_model = specific_model_data['model']\n",
    "    specific_accuracy = specific_model_data['accuracy']\n",
    "    specific_precision = specific_model_data['precision']\n",
    "    print(f\"Specific Model: {specific_model}, Accuracy: {specific_accuracy}, Precision: {specific_precision}\")\n",
    "else:\n",
    "    print(f\"Model '{specific_model_name}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(max_iter=1000), Predictions: [0 0 0 ... 1 0 1]\n",
      "Model: RidgeClassifier(alpha=0.005), Predictions: [0 0 0 ... 1 0 1]\n",
      "Model: LinearSVC(dual=False), Predictions: [0 0 0 ... 1 0 1]\n",
      "Model: SVC(), Predictions: [0 0 0 ... 1 0 1]\n",
      "Model: KNeighborsClassifier(), Predictions: [0 0 1 ... 1 0 1]\n",
      "Model: DecisionTreeClassifier(), Predictions: [0 0 1 ... 1 0 1]\n",
      "Model: RandomForestClassifier(), Predictions: [0 0 1 ... 1 0 1]\n",
      "Model: AdaBoostClassifier(), Predictions: [0 0 1 ... 1 0 1]\n",
      "Model: MLPClassifier(), Predictions: [0 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the new data\n",
    "\n",
    "# Preprocess the new data (if needed)\n",
    "# Make sure it has the same format as the data used for training the models\n",
    "\n",
    "# Load the models from the saved file\n",
    "with open('saved_models.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "    models_dict = loaded_data[1]  # Assuming the models are saved in the second element of the tuple\n",
    "\n",
    "# Make predictions using the loaded models\n",
    "for model_name, model_data in models_dict.items():\n",
    "    model = model_data['model']\n",
    "    y_pred = model.predict(X_test)  # Assuming new_data has the same features as X_train\n",
    "    print(f\"Model: {model_name}, Predictions: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Access the models dictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "with open('models.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# Access the models dictionary\n",
    "models_dict = data['model']\n",
    "\n",
    "# Assuming index 5 contains the trained DecisionTreeClassifier model\n",
    "best_model = models_dict\n",
    "\n",
    "# Now you can use the best_model for prediction\n",
    "# For example, if you have some new data 'X_test', you can predict using:\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model from the file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update with your file path\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Check if the loaded object is an instance of RandomForestClassifier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pishing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier  # Assuming RandomForestClassifier is the model you're using\n",
    "\n",
    "# Load the model from the file\n",
    "model_file_path = 'models.pkl'  # Update with your file path\n",
    "with open(model_file_path, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Check if the loaded object is an instance of RandomForestClassifier\n",
    "if isinstance(loaded_model, RandomForestClassifier):\n",
    "    print(\"Model loaded successfully and is an instance of RandomForestClassifier.\")\n",
    "else:\n",
    "    print(\"Error: The loaded object is not an instance of RandomForestClassifier.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pishing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
